ğŸš— Otonom SÃ¼rÃ¼ÅŸ Ä°Ã§in VLM TabanlÄ± Karar Destek MekanizmasÄ±

(VLM-Based Decision Making Mechanism for Autonomous Driving)

"AlgÄ±layan araÃ§lardan, dÃ¼ÅŸÃ¼nen ve anlayan araÃ§lara..."

ğŸ“‹ Proje Ã–zeti ve Kapsam

Bu proje, geleneksel otonom sÃ¼rÃ¼ÅŸ algoritmalarÄ±nÄ±n (kural tabanlÄ± veya uÃ§tan uca kara kutu modelleri) yetersiz kaldÄ±ÄŸÄ± karmaÅŸÄ±k trafik senaryolarÄ±nda, BÃ¼yÃ¼k Dil Modelleri (LLM) ve GÃ¶rme-Dil Modellerini (VLM) bir "YÃ¼ksek Seviyeli Karar Verici" (High-Level Decision Maker) olarak konumlandÄ±ran hibrit bir mimari sunmaktadÄ±r.

Projenin temel amacÄ±, aracÄ±n sadece Ã§evresel nesneleri algÄ±lamasÄ±nÄ± deÄŸil, olaylar arasÄ±nda nedensel iliÅŸkiler kurmasÄ±nÄ± (Ã¶rneÄŸin: "Top yola yuvarlandÄ± -> Ã‡ocuk Ã§Ä±kabilir -> YavaÅŸla") saÄŸlamaktÄ±r.

ğŸ— Mimari YaklaÅŸÄ±m: Sistem 1 ve Sistem 2

Bu projede, Nobel Ã¶dÃ¼llÃ¼ Daniel Kahneman'Ä±n "HÄ±zlÄ± ve YavaÅŸ DÃ¼ÅŸÃ¼nme" teorisi otonom sÃ¼rÃ¼ÅŸe uyarlanmÄ±ÅŸtÄ±r:

ğŸ§  Sistem 2 (VLM AjanÄ± - YavaÅŸ DÃ¼ÅŸÃ¼nme): KarmaÅŸÄ±k ve belirsiz durumlarda devreye giren, stratejik kararlar alan ve muhakeme yeteneÄŸi olan katman. (Ã–rn: "Agresif sÃ¼rÃ¼cÃ¼den kaÃ§Ä±nmak iÃ§in ÅŸerit deÄŸiÅŸtir.").

ğŸ›¡ï¸ Sistem 1 (GÃ¼venlik KatmanÄ± - HÄ±zlÄ± DÃ¼ÅŸÃ¼nme): Deterministik, milisaniye hassasiyetinde Ã§alÄ±ÅŸan ve VLM'in olasÄ± halÃ¼sinasyonlarÄ±nÄ± filtreleyen gÃ¼venlik bariyeri (Safety Guard/LLM-Hinted RL).

âœ¨ Temel Ã–zellikler

Zincirleme DÃ¼ÅŸÃ¼nce (Chain-of-Thought - CoT): Model, "Fren yap" demeden Ã¶nce neden fren yapmasÄ± gerektiÄŸini adÄ±m adÄ±m aÃ§Ä±klar (ÅeffaflÄ±k).

HalÃ¼sinasyon Filtresi: LLM'in Ã¼rettiÄŸi aksiyonlar, fiziksel kurallar ve sensÃ¶r verileriyle (mesafe, hÄ±z) Ã§apraz kontrolden geÃ§irilir.

Senaryo BazlÄ± SimÃ¼lasyon: Okul bÃ¶lgesi, agresif sÃ¼rÃ¼cÃ¼ ve otoyol senaryolarÄ± Ã¼zerinde karar mekanizmasÄ± testi.

ğŸ“‚ Proje YapÄ±sÄ±

.
â”œâ”€â”€ main.py                 # SimÃ¼lasyonu baÅŸlatan ana dosya
â”œâ”€â”€ config.py               # Model konfigÃ¼rasyonlarÄ±
â”œâ”€â”€ requirements.txt        # Gerekli kÃ¼tÃ¼phaneler
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ perception.py       # (Mock) SensÃ¶r ve sahne verisi Ã¼retici
â”‚   â”œâ”€â”€ vlm_agent.py        # Karar veren LLM/VLM AjanÄ± (Reasoning)
â”‚   â””â”€â”€ safety_guard.py     # KararlarÄ± denetleyen GÃ¼venlik KatmanÄ±
â””â”€â”€ assets/
    â””â”€â”€ architecture.png    # Mimari diyagram


ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Repoyu klonlayÄ±n:

git clone [https://github.com/kullaniciadi/llm-autonomous-driving.git](https://github.com/kullaniciadi/llm-autonomous-driving.git)
cd llm-autonomous-driving


Gereksinimleri yÃ¼kleyin:

pip install -r requirements.txt


SimÃ¼lasyonu baÅŸlatÄ±n:

python main.py


ğŸ§ª Deneysel Senaryolar (Demo)

Bu repo, raporda belirtilen teorik riskleri analiz etmek iÃ§in aÅŸaÄŸÄ±daki senaryolarÄ± simÃ¼le eder:

Senaryo

VLM Tespiti (Sistem 2)

GÃ¼venlik MÃ¼dahalesi (Sistem 1)

SonuÃ§

Okul BÃ¶lgesi

"Ã‡ocuk Ã§Ä±kabilir, riskli bÃ¶lge."

HÄ±z SÄ±nÄ±rÄ± KontrolÃ¼ (Max 30km/s)

âœ… GÃ¼venli YavaÅŸlama

Agresif SÃ¼rÃ¼cÃ¼

"Arkada taciz eden araÃ§ var, yol ver."

Åerit MÃ¼saitliÄŸi KontrolÃ¼

âœ… Åerit DeÄŸiÅŸtirme

HatalÄ± Karar (Test)

"Yol boÅŸ, hÄ±zlan." (HalÃ¼sinasyon)

Ã–n Engel Mesafe < 10m

ğŸ›‘ ACÄ°L FREN (MÃ¼dahale)

ğŸ“š LiteratÃ¼r ve Referanslar

Bu Ã§alÄ±ÅŸma, aÅŸaÄŸÄ±daki temel literatÃ¼r Ã¼zerine inÅŸa edilmiÅŸtir (Tam liste proje raporundadÄ±r):

GAIA-1: Otonom sÃ¼rÃ¼ÅŸ iÃ§in Ã¼retken dÃ¼nya modelleri.

DriveGPT: SÃ¼rÃ¼ÅŸ davranÄ±ÅŸlarÄ±nÄ±n tokenizasyonu ve tahmini.

DiLu Framework: KapalÄ± dÃ¶ngÃ¼ Ã¶ÄŸrenme ve bellek yÃ¶netimi.

DriveAgent-R1: Aktif algÄ± ve hibrit dÃ¼ÅŸÃ¼nme.

ğŸ”— KatkÄ± ve Ä°letiÅŸim

Bu proje, [Ders AdÄ±/Proje AdÄ±] kapsamÄ±nda geliÅŸtirilmiÅŸtir.

GeliÅŸtirici: [AdÄ±n SoyadÄ±n]

Ä°letiÅŸim: [E-posta Adresin]

Not: Bu proje bir "Proof of Concept" (Kavram KanÄ±tÄ±) Ã§alÄ±ÅŸmasÄ±dÄ±r ve gerÃ§ek araÃ§larda doÄŸrudan kullanÄ±m iÃ§in tasarlanmamÄ±ÅŸtÄ±r.
